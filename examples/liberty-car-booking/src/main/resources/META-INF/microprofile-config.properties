# Microprofile server properties
server.port=9080


dev.langchain4j.plugin.chat-model.class=dev.langchain4j.model.ollama.OllamaChatModel
dev.langchain4j.plugin.chat-model.config.base-url=http://localhost:11434
dev.langchain4j.plugin.chat-model.config.temperature=0.1
dev.langchain4j.plugin.chat-model.config.model-name=llama3.1:latest
dev.langchain4j.plugin.chat-model.config.log-requests=true
dev.langchain4j.plugin.chat-model.config.log-responses=true
dev.langchain4j.plugin.chat-model.config.listener=factory:Listener1


dev.langchain4j.plugin.docRagRetriever.class=dev.langchain4j.rag.content.retriever.EmbeddingStoreContentRetriever
dev.langchain4j.plugin.docRagRetriever.config.embeddingStore=lookup:@default
dev.langchain4j.plugin.docRagRetriever.config.embeddingModel=lookup:@default
dev.langchain4j.plugin.docRagRetriever.config.maxResults=3
dev.langchain4j.plugin.docRagRetriever.config.minScore=0.6

# Chat Memory used by ChatAiService class
dev.langchain4j.plugin.chat-ai-service-memory.class=dev.langchain4j.memory.chat.MessageWindowChatMemory
dev.langchain4j.plugin.chat-ai-service-memory.scope=jakarta.enterprise.context.ApplicationScoped
dev.langchain4j.plugin.chat-ai-service-memory.config.maxMessages=10

# Chat Memory used by FraudAiService class
dev.langchain4j.plugin.fraud-ai-service-memory.class=dev.langchain4j.memory.chat.MessageWindowChatMemory
dev.langchain4j.plugin.fraud-ai-service-memory.scope=jakarta.enterprise.context.ApplicationScoped
dev.langchain4j.plugin.fraud-ai-service-memory.config.maxMessages=5

# Location of documents to RAG
app.docs-for-rag.dir=docs-for-rag

# Microprofile Telemetry
otel.service.name=liberty-car-booking
otel.sdk.disabled=false
otel.logs.exporter=otlp,console
otel.metrics.exporter=otlp,console
otel.traces.exporter=otlp,console
